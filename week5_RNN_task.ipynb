{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Copy of RNN-task.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ls_ANJ-mxLBx",
        "colab_type": "code",
        "outputId": "fe4dcad0-9ae6-4e24-e345-de3afaa2afc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "! shred -u setup_google_colab.py\n",
        "! wget https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py -O setup_google_colab.py\n",
        "import setup_google_colab\n",
        "setup_google_colab.setup_week5()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shred: setup_google_colab.py: failed to open for writing: No such file or directory\n",
            "--2020-04-02 02:21:39--  https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3636 (3.6K) [text/plain]\n",
            "Saving to: ‘setup_google_colab.py’\n",
            "\n",
            "setup_google_colab. 100%[===================>]   3.55K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-04-02 02:21:44 (69.6 MB/s) - ‘setup_google_colab.py’ saved [3636/3636]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6nG6bu8jEdd",
        "colab_type": "code",
        "outputId": "6b525c7e-0b7d-4f4b-d6ab-ceea6294d3ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# set tf 1.x for colab\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXa1qTpujEdm",
        "colab_type": "text"
      },
      "source": [
        "# Generating names with recurrent neural networks\n",
        "\n",
        "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
        "\n",
        "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
        "\n",
        "It's dangerous to go alone, take these:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.696201Z",
          "start_time": "2018-08-13T20:26:38.104103Z"
        },
        "id": "nApdezsgjEdn",
        "colab_type": "code",
        "outputId": "72cce9b6-da6a-4155-b0e8-65db74147a5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "import keras_utils\n",
        "import tqdm_utils"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62Hb9At9jEdv",
        "colab_type": "text"
      },
      "source": [
        "# Load data\n",
        "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
        "\n",
        "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.701832Z",
          "start_time": "2018-08-13T20:26:42.697766Z"
        },
        "id": "AjS6E0JJjEdw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start_token = \" \"  # so that the network knows that we're generating a first token\n",
        "\n",
        "# this is the token for padding,\n",
        "# we will add fake pad token at the end of names \n",
        "# to make them of equal size for further batching\n",
        "pad_token = \"#\"\n",
        "\n",
        "with open(\"names\") as f:\n",
        "    names = f.read()[:-1].split('\\n')\n",
        "    names = [start_token + name for name in names]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.707885Z",
          "start_time": "2018-08-13T20:26:42.703302Z"
        },
        "id": "zsgPIdN4jEd2",
        "colab_type": "code",
        "outputId": "92cb53de-ba81-49cb-dc56-cbfd3f094242",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "print('number of samples:', len(names))\n",
        "for x in names[::1000]:\n",
        "    print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of samples: 7944\n",
            " Abagael\n",
            " Claresta\n",
            " Glory\n",
            " Liliane\n",
            " Prissie\n",
            " Geeta\n",
            " Giovanne\n",
            " Piggy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.857411Z",
          "start_time": "2018-08-13T20:26:42.709371Z"
        },
        "id": "bqVK7u06jEd6",
        "colab_type": "code",
        "outputId": "fd8ef33c-31ec-4f88-86d9-2eb6e004e959",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "MAX_LENGTH = max(map(len, names))\n",
        "print(\"max length:\", MAX_LENGTH)\n",
        "\n",
        "plt.title('Sequence length distribution')\n",
        "plt.hist(list(map(len, names)), bins=25);"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max length: 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQ9/MLCMOfTOzjPx/p/4cUF1Gcl0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wo5rZrgjjEeA",
        "colab_type": "text"
      },
      "source": [
        "# Text processing\n",
        "\n",
        "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.864592Z",
          "start_time": "2018-08-13T20:26:42.858725Z"
        },
        "id": "R_48_wk2jEeB",
        "colab_type": "code",
        "outputId": "a79d3445-a389-4268-9a62-fcd15da4b9df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tokens = set(''.join(names)) ### YOUR CODE HERE: all unique characters go here, padding included!\n",
        "\n",
        "tokens = list(tokens)\n",
        "tokens.append(pad_token)\n",
        "n_tokens = len(tokens)\n",
        "print ('n_tokens:', n_tokens)\n",
        "\n",
        "assert 50 < n_tokens < 60"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n_tokens: 56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHMF2ETyjEeG",
        "colab_type": "text"
      },
      "source": [
        "### Cast everything from symbols into identifiers\n",
        "\n",
        "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
        "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
        "\n",
        "To create such dictionary, let's assign `token_to_id`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.870330Z",
          "start_time": "2018-08-13T20:26:42.866135Z"
        },
        "id": "0KqYsDGUjEeH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token_to_id = {} ### YOUR CODE HERE: create a dictionary of {symbol -> its  index in tokens}\n",
        "for index, token in enumerate(tokens):\n",
        "    token_to_id[token] = index\n",
        "    \n",
        "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.875943Z",
          "start_time": "2018-08-13T20:26:42.871834Z"
        },
        "id": "RBRKu68jjEeK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_matrix(names, max_len=None, pad=token_to_id[pad_token], dtype=np.int32):\n",
        "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
        "    \n",
        "    max_len = max_len or max(map(len, names))\n",
        "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
        "\n",
        "    for i in range(len(names)):\n",
        "        name_ix = list(map(token_to_id.get, names[i]))\n",
        "        names_ix[i, :len(name_ix)] = name_ix\n",
        "\n",
        "    return names_ix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.883107Z",
          "start_time": "2018-08-13T20:26:42.877186Z"
        },
        "id": "TPcZjmI_jEeO",
        "colab_type": "code",
        "outputId": "f5c9befe-138c-4f35-efc0-24375f507f38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        }
      },
      "source": [
        "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
        "print('\\n'.join(names[::2000]))\n",
        "print(to_matrix(names[::2000]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Abagael\n",
            " Glory\n",
            " Prissie\n",
            " Giovanne\n",
            "[[22 49 46 16 21 16 32 48 55]\n",
            " [22 45 48 14 37 43 55 55 55]\n",
            " [22 54 37 35  3  3 35 32 55]\n",
            " [22 45 35 14 51 16  6  6 32]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9nJ84K3jEeT",
        "colab_type": "text"
      },
      "source": [
        "# Defining a recurrent neural network\n",
        "\n",
        "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/rnn.png?raw=1\" width=600>\n",
        "\n",
        "Since we're training a language model, there should also be:\n",
        "* An embedding layer that converts character id x_t to a vector.\n",
        "* An output layer that predicts probabilities of next phoneme based on h_t+1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.039419Z",
          "start_time": "2018-08-13T20:26:42.884581Z"
        },
        "id": "YiLOowbOjEeU",
        "colab_type": "code",
        "outputId": "6bec5e46-5f24-4296-8f73-7b9ffb4d98e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "# remember to reset your session if you change your graph!\n",
        "s = keras_utils.reset_tf_session()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/keras_utils.py:68: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:79: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:82: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:84: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/keras_utils.py:75: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/keras_utils.py:77: The name tf.InteractiveSession is deprecated. Please use tf.compat.v1.InteractiveSession instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.044903Z",
          "start_time": "2018-08-13T20:26:44.041084Z"
        },
        "id": "tetEy1rNjEeY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.layers import concatenate, Dense, Embedding\n",
        "\n",
        "rnn_num_units = 64  # size of hidden state\n",
        "embedding_size = 16  # for characters\n",
        "\n",
        "# Let's create layers for our recurrent network\n",
        "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
        "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
        "\n",
        "# an embedding layer that converts character ids into embeddings\n",
        "embed_x = Embedding(n_tokens, embedding_size)\n",
        "\n",
        "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
        "get_h_next = Dense(rnn_num_units, activation = 'relu') ### YOUR CODE HERE\n",
        "\n",
        "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
        "get_probas = Dense(n_tokens, activation = 'softmax') ### YOUR CODE HERE "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4OMjo1ajEec",
        "colab_type": "text"
      },
      "source": [
        "We will generate names character by character starting with `start_token`:\n",
        "\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/char-nn.png?raw=1\" width=600>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.053212Z",
          "start_time": "2018-08-13T20:26:44.048389Z"
        },
        "id": "ZEjpmb99jEed",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rnn_one_step(x_t, h_t):\n",
        "    \"\"\"\n",
        "    Recurrent neural network step that produces \n",
        "    probabilities for next token x_t+1 and next state h_t+1\n",
        "    given current input x_t and previous state h_t.\n",
        "    We'll call this method repeatedly to produce the whole sequence.\n",
        "    \n",
        "    You're supposed to \"apply\" above layers to produce new tensors.\n",
        "    Follow inline instructions to complete the function.\n",
        "    \"\"\"\n",
        "    # convert character id into embedding\n",
        "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
        "    \n",
        "    # concatenate x_t embedding and previous h_t state\n",
        "    x_and_h = tf.concat([x_t_emb, h_t], 1) ### YOUR CODE HERE\n",
        "    \n",
        "    # compute next state given x_and_h\n",
        "    h_next = get_h_next(x_and_h) ### YOUR CODE HERE\n",
        "    \n",
        "    # get probabilities for language model P(x_next|h_next)\n",
        "    output_probas = get_probas(h_next) ### YOUR CODE HERE\n",
        "    \n",
        "    return output_probas, h_next"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymL0ZDRsjEeh",
        "colab_type": "text"
      },
      "source": [
        "# RNN: loop\n",
        "\n",
        "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
        "\n",
        "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.342948Z",
          "start_time": "2018-08-13T20:26:44.056136Z"
        },
        "id": "67y9KL9AjEeh",
        "colab_type": "code",
        "outputId": "c4eb4017-095b-4d61-8971-55455264e51e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
        "batch_size = tf.shape(input_sequence)[0]\n",
        "\n",
        "predicted_probas = []\n",
        "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
        "\n",
        "for t in range(MAX_LENGTH):\n",
        "    x_t = input_sequence[:, t]  # column t\n",
        "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
        "    \n",
        "    h_prev = h_next\n",
        "    predicted_probas.append(probas_next)\n",
        "    \n",
        "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
        "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
        "\n",
        "# next to last token prediction is not needed\n",
        "predicted_probas = predicted_probas[:, :-1, :]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3535: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4K5F4njjEel",
        "colab_type": "text"
      },
      "source": [
        "# RNN: loss and gradients\n",
        "\n",
        "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
        "\n",
        "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
        "\n",
        "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.354310Z",
          "start_time": "2018-08-13T20:26:44.344648Z"
        },
        "id": "Zp93NnNXjEem",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# flatten predictions to [batch*time, n_tokens]\n",
        "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
        "\n",
        "# flatten answers (next tokens) and one-hot encode them\n",
        "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFoihtXjjEeq",
        "colab_type": "text"
      },
      "source": [
        "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
        "\n",
        "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
        "\n",
        "For simplicity you can ignore this comment, it's up to you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:45.076642Z",
          "start_time": "2018-08-13T20:26:44.355594Z"
        },
        "id": "tF0FGbd_jEer",
        "colab_type": "code",
        "outputId": "5007649a-5918-4eff-a76a-35e18ab72a8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        }
      },
      "source": [
        "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
        "# Mind that predictions are probabilities and NOT logits!\n",
        "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
        "from keras.objectives import categorical_crossentropy\n",
        "\n",
        "loss = tf.reduce_mean(categorical_crossentropy(answers_matrix, predictions_matrix))### YOUR CODE HERE\n",
        "\n",
        "optimize = tf.train.AdamOptimizer().minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2745: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2749: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbH10LfOjEeu",
        "colab_type": "text"
      },
      "source": [
        "# RNN: training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.322187Z",
          "start_time": "2018-08-13T20:26:45.078296Z"
        },
        "id": "gkLpYo9UjEeu",
        "colab_type": "code",
        "outputId": "8258fe56-849a-4507-a8da-b22ef9dc7613",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "batch_size = 32\n",
        "history = []\n",
        "\n",
        "for i in range(1000):\n",
        "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
        "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
        "    \n",
        "    history.append(loss_i)\n",
        "    \n",
        "    if (i + 1) % 100 == 0:\n",
        "        clear_output(True)\n",
        "        plt.plot(history, label='loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deXhU1fnA8e+bmUkCJOxhRwKyyyoB\nQQRRAUXF3Sqta91rba12QXGtVOvSqlRb60/c6lKtWkVQQAQrICAB2RFB1rAGCAESss75/XHvTGYm\nM5nJRsid9/M8eZi598zcc3PDe889qxhjUEopVf8l1HUGlFJK1QwN6Eop5RAa0JVSyiE0oCullENo\nQFdKKYdw19WBW7ZsadLT0+vq8EopVS8tW7ZsvzEmLdy+Ogvo6enpZGZm1tXhlVKqXhKRbZH2aZWL\nUko5hAZ0pZRyCA3oSinlEHVWh66UUjWhuLiYrKwsCgoK6jorNSo5OZkOHTrg8Xhi/owGdKVUvZaV\nlUVqairp6emISF1np0YYYzhw4ABZWVl07tw55s9plYtSql4rKCigRYsWjgnmACJCixYtKv3UEXNA\nFxGXiHwnItPD7EsSkfdEZJOILBGR9ErlQimlqsFJwdynKudUmRL6r4H1EfbdBOQYY7oCzwJPVjon\nMfox+yiPfrqWohJvbR1CKaXqpZgCuoh0AC4AXomQ5GLgDfv1B8A5Uku3zO0H8nlt4VZmr9tTG1+v\nlFKVlpKSUtdZAGIvoT8H/B6IVCxuD+wAMMaUALlAi9BEInKriGSKSGZ2dnYVsgsju6fRsXkD/rUo\n4mAppZSKS1EDuohcCOwzxiyr7sGMMS8bYzKMMRlpaWGnIojKlSD87LROLNlykB/2HqlulpRSqsYY\nY/jd735Hnz596Nu3L++99x4Au3fvZuTIkQwYMIA+ffowf/58SktLueGGG/xpn3322WofP5Zui8OB\ni0TkfCAZaCwibxljrglIsxPoCGSJiBtoAhyodu4iuHJQB56c+T2fr95D99aptXUYpVQ98+ina1m3\n63CNfmfvdo15ePwpMaX96KOPWLFiBStXrmT//v0MHjyYkSNH8s4773DuuecyadIkSktLyc/PZ8WK\nFezcuZM1a9YAcOjQoWrnNWoJ3RhznzGmgzEmHbgamBsSzAGmAdfbr6+w09TaYqUtUpLo2aYxmdsO\n1tYhlFKq0hYsWMCECRNwuVy0bt2aM888k6VLlzJ48GBee+01HnnkEVavXk1qaipdunRh8+bN3HXX\nXcycOZPGjRtX+/hVHlgkIn8EMo0x04CpwL9EZBNwECvw16pebVP5ZlOtPQQopeqhWEvSx9vIkSP5\n+uuvmTFjBjfccAP33HMP1113HStXrmTWrFm89NJLvP/++7z66qvVOk6lBhYZY74yxlxov37IDuYY\nYwqMMVcaY7oaY4YYYzZXK1cx6NOuCXsOF7DjYH5tH0oppWIyYsQI3nvvPUpLS8nOzubrr79myJAh\nbNu2jdatW3PLLbdw8803s3z5cvbv34/X6+Xyyy9n8uTJLF++vNrHr7dD/8/o1hKApVsP0rF5wzrO\njVJKwaWXXsqiRYvo378/IsJTTz1FmzZteOONN3j66afxeDykpKTw5ptvsnPnTm688Ua8Xqvz4BNP\nPFHt40stVnVXKCMjw1RngYviUi+9H5rJTWd0YeK4njWYM6VUfbJ+/Xp69epV19moFeHOTUSWGWMy\nwqWvt3O5eFwJdGzWkB05WuWilFJQjwM6QKvGSew77KwpM5VSqqrqdUBv0ziZvYcL6zobSqk6VldV\nx7WpKudUrwN668bJ7Dlc4MiLqZSKTXJyMgcOHHBUHPDNh56cnFypz9XbXi4ArRonU1TiJfdYMU0b\nJtZ1dpRSdaBDhw5kZWVR1fmhTlS+FYsqo14H9NaNkwDYc7hAA7pSccrj8VRqVR8nq9dVLi1TrIB+\n8GhRHedEKaXqXr0O6M3sUnlOfnEd50QppepePQ/o1mrYB/O1hK6UUvU6oPvqzQ/laUBXSql6HdAT\n3Qk0SnRplYtSSlHPAzpYpfQcrXJRSqn6H9CbNfJoQFdKKZwQ0BsmkqN16EopVf8DetOGieQe0zp0\npZSq9wG9cbKbIwUldZ0NpZSqc/U/oDfwcLig2FET8yilVFXU/4Ce7KG41FBQ7K3rrCilVJ2q/wG9\ngTW/mNajK6XiXb0P6I0SrYCeX6T16Eqp+FbvA3qS2zoFrXJRSsW7qAFdRJJF5FsRWSkia0Xk0TBp\nbhCRbBFZYf/cXDvZLS/Z4wKgsKT0eB1SKaVOSLEscFEInG2MOSoiHmCBiHxujFkcku49Y8wvaz6L\nFUvyaAldKaUghoBurP6AR+23HvvnhOkj6CuhF2gJXSkV52KqQxcRl4isAPYBXxhjloRJdrmIrBKR\nD0SkY4TvuVVEMkUks6bW//PVoRcWa0BXSsW3mAK6MabUGDMA6AAMEZE+IUk+BdKNMf2AL4A3InzP\ny8aYDGNMRlpaWnXy7VdWh65VLkqp+FapXi7GmEPAPOC8kO0HjDGF9ttXgEE1k73o/FUuWkJXSsW5\nWHq5pIlIU/t1A2AM8H1ImrYBby8C1tdkJiuSrN0WlVIKiK2XS1vgDRFxYd0A3jfGTBeRPwKZxphp\nwK9E5CKgBDgI3FBbGQ6VpCV0pZQCYuvlsgoYGGb7QwGv7wPuq9msxcZXQtc6dKVUvKv3I0XdrgTc\nCaIldKVU3Kv3AR2shlGtQ1dKxTtHBPQkd4IOLFJKxT1HBPRkj4tCLaErpeKcIwJ6kkdL6Eop5YiA\nnux26dB/pVTcc0RAT/IkaKOoUiruOSKgJ7tdOh+6UiruOSOgawldKaWcEtBdOrBIKRX3HBHQk9wJ\nOvRfKRX3HBHQtYSulFIa0JVSyjEcEdCtgUVa5aKUim/OCOhuF0UlXqz1rJVSKj45IqAne3ROdKWU\nckRAT3RZp1FUqgFdKRW/HBHQPXZAL9YSulIqjjkioLtdAkCJV+vQlVLxyxEB3V9C1yoXpVQcc0hA\nt0roxaVaQldKxS+HBHTrNEq0hK6UimOOCOjuBO3lopRSjgjoviqXEq1yUUrFsagBXUSSReRbEVkp\nImtF5NEwaZJE5D0R2SQiS0QkvTYyG4k2iiqlVGwl9ELgbGNMf2AAcJ6IDA1JcxOQY4zpCjwLPFmz\n2ayYWxtFlVIqekA3lqP2W4/9Exo5LwbesF9/AJwjIlJjuYzCN1K0xKsldKVU/IqpDl1EXCKyAtgH\nfGGMWRKSpD2wA8AYUwLkAi3CfM+tIpIpIpnZ2dnVy3kAt1a5KKVUbAHdGFNqjBkAdACGiEifqhzM\nGPOyMSbDGJORlpZWla8IS/uhK6VUJXu5GGMOAfOA80J27QQ6AoiIG2gCHKiJDMZCG0WVUiq2Xi5p\nItLUft0AGAN8H5JsGnC9/foKYK45jpOTuxO026JSSrljSNMWeENEXFg3gPeNMdNF5I9ApjFmGjAV\n+JeIbAIOAlfXWo7D8Oj0uUopFT2gG2NWAQPDbH8o4HUBcGXNZi12ZUP/tYSulIpfzhopqt0WlVJx\nzBEB3ddtsUgXuFBKxTFHBPSygUVa5aKUil+OCOj+of9aQldKxTFnBHS722KxltCVUnHMEQFdRPC4\nRAcWKaXimiMCOliLXOiKRUqpeOaYgG6V0LXKRSkVvxwU0BO0ykUpFdccFdB1pKhSKp45JqC7tVFU\nKRXnHBPQPa4EnZxLKRXXHBTQRatclFJxzTEB3Z2QoJNzKaXimmMCusedQJGW0JVSccw5AT1BdGCR\nUiquOSegaz90pVScc0xAd+tIUaVUnHNMQE90aaOoUiq+OSagu11CcYmW0JVS8csxAd3jSqBYS+hK\nqTjmrICujaJKqTjmoICuI0WVUvEtakAXkY4iMk9E1onIWhH5dZg0o0QkV0RW2D8P1U52I3NrCV0p\nFefcMaQpAe41xiwXkVRgmYh8YYxZF5JuvjHmwprPYmwSXQnabVEpFdeiltCNMbuNMcvt10eA9UD7\n2s5YZbkTdPpcpVR8q1QduoikAwOBJWF2DxORlSLyuYicEuHzt4pIpohkZmdnVzqzFfG4dYELpVR8\nizmgi0gK8CFwtzHmcMju5UAnY0x/4G/Ax+G+wxjzsjEmwxiTkZaWVtU8h+VJEIpKvRijQV0pFZ9i\nCugi4sEK5m8bYz4K3W+MOWyMOWq//gzwiEjLGs1pFB6XdSqlXg3oSqn4FEsvFwGmAuuNMX+NkKaN\nnQ4RGWJ/74GazGg0bjuga8OoUipexdLLZThwLbBaRFbY2+4HTgIwxrwEXAHcISIlwDHganOc6z48\nLgGg2OulAa7jeWillDohRA3oxpgFgERJ8wLwQk1lqip8VS7FJdrTRSkVnxwzUtRtl9BLtA5dKRWn\nHBPQfSX0Ii2hK6XilIMCupbQlVLxzUEB3dfLRUvoSqn45JiA7k7QgK6Uim+OCeiJbrvbovZDV0rF\nKccEdF8JvURL6EqpOOWYgO7v5aIBXSkVpxwT0LXKRSkV7xwT0JPc1nD/wuLSOs6JUkrVDccE9ES3\nVrkopeKbYwJ6kh3QC4s1oCul4pNjArqW0JVS8c4xAV3r0JVS8c4xAV1L6EqpeOeYgK516EqpeOeY\ngO5OEBJES+hKqfjlmIAuIiS6EyjU+dCVUnHKMQEdINnj4liRNooqpeKTowJ6arKbIwXFdZ0NpZSq\nE84K6EkejhSU1HU2lFKqTjgqoDdu4OawltCVUnHKUQE9NVlL6Eqp+BU1oItIRxGZJyLrRGStiPw6\nTBoRkSkisklEVonIqbWT3YqlJrk1oCul4pY7hjQlwL3GmOUikgosE5EvjDHrAtKMA7rZP6cB/7D/\nPa4aJLo4pkP/lVJxKmoJ3Riz2xiz3H59BFgPtA9JdjHwprEsBpqKSNsaz20UDRO126JSKn5Vqg5d\nRNKBgcCSkF3tgR0B77MoH/QRkVtFJFNEMrOzsyuX0xg08FgldGN01SKlVPyJOaCLSArwIXC3MeZw\nVQ5mjHnZGJNhjMlIS0uryldUKDnRnnFRR4sqpeJQTAFdRDxYwfxtY8xHYZLsBDoGvO9gbzuuGnis\ngJ6v1S5KqTgUSy8XAaYC640xf42QbBpwnd3bZSiQa4zZXYP5jElDu4S+9UAeXq9Wuyil4kssJfTh\nwLXA2SKywv45X0RuF5Hb7TSfAZuBTcD/Ab+onexWLNkuoV/292+YMncjAMeKSlmdlVsX2VFKqeMq\nardFY8wCQKKkMcCdNZWpqmrWMNH/esHG/dw9uju//vd3zF63l9WPjCU12VOHuVNKqdrlqJGibZsk\n+197XNapLdi0H0D7pyulHM9RAb1NQEAvNYb9Rwv9gVxXMlJKOV0sI0XrjZSkstP5dstBMibP8b8v\n0BK6UsrhHFVCtzrkhKdVLkopp3NUQK9IgVa5KKUcLm4C+k/+uYhN+47UdTaUUqrWxE1AB3hv6Y7o\niZRSqp6Kq4BeoqNHlVIOFlcBvTRCQK/uNAFZOfnszj1Wre9QSqnqclxA903QFU64EvrqrFy63P8Z\n39gDkKrijCfnMeyJuVX+vFJK1QTHBfRvJp4dcV9pafmAvmizFcjnrN/n31Zc6uXaqUtYuvVgzWdQ\nKaVqieMCerNGiRH3hSuhJ4Tpu745O4/5G/fzhw9W1WjelFKqNjlqpGg0Hy7PokFiAiO7peFxJ7Bk\n80FyjxUDYCgL9rvs+vB2TRvUST6VUqoq4iqgA7y1eDtvLd5ebnvgqnW5+VaQT/a42JNbEDRHjFJK\nnagcV+VSXV6vYdbaPQDMWb+XoU98Wcc5Ukqp2GhAD+D1Gt5YtJXP1+wJ2l5cqtMGKKVOfHFX5RJJ\nYYmXfo/O5mhhSbl9x4pL/fOrK6XUiSouotRJzRtGTZNfVBI2mIO1jF0sso8Uxpynz1bvJn3iDPYd\nLoj5M0opVRFHB/R5vx3Fp788g//+4nQ++sXpFabNK4wctI8VlWKM4fPVuyksCU73+eqytbD/OH1d\n2M+/Mn8zo56eB1ijVacu2MLrC7cCsHb34VhORSmlonJ0lUvnlo38r1ukJFWYNi9C6Rwgv6iUrzZk\nc8fby/nV2V25Z2wPAIwx3PH2cn+6Um/4uvbJM9b7X3+2ejePBQT+4hKtn1dK1QxHl9ArI78ockA/\nVlzC1gN5AByy+61D+YFKJoYpYQpDAnhxmNGrSilVFY4uoVfG2l2Rqz7yi0o5ZPdNb9rA498eqffL\ntVOX0KFZAyae14tPVu70bzfG4HEFj0zVHjRKqZoSlwH9uasGcPd7K2jbJJnduVajZEVT6+7MOcaR\nAqsE37iBhx/2HqHUa2jXJPxI0vkbrflhDhwtYva6vf7tpV6DOyH4oaiogoBe6jUUlXhpkBh5wjGl\nlPKJyyqXiwe0Y/ZvRnLN0E4xpX9z0TZeXbjF/37ss18z7vn5FQZjgO0H84Pel3gN7pASuq8KZv7G\nbE57fE5Qj5p73l9Br4dmxpRHpZSKGtBF5FUR2SciayLsHyUiuSKywv55qOazWTOWThrNovvORkTo\n3jqVJgHVJxVZF9ATJTCIh1aXGAPrAqpu8kO6O5Z4Db/+93dB247ZdfePf/Y9ew8X8mP2Uf++T1bs\niil/SikFsZXQXwfOi5JmvjFmgP3zx+pnq3akpSbRNqCaJDW58jVOxSVlVTOhAT0nv4jzp8z3vw8N\n6Cu2Hyq3WPVRu7ukb9yS125ZPVJQ1vgaaWGOQGt35fLe0vJz1Cil4kfUiGaM+VpE0ms/KzWnS1oj\n2scwU2K/Dk0BaN4okYN5RTF9d1FpWZDevD8vaN+SLcHzpx8L6TlzzdQl5b4v3+4u6bKn8S31GgqK\nS+n7yGx/muJSL66EiuvRL5iyAICrBp8U7RSUUg5VU42iw0RkJbAL+K0xZm24RCJyK3ArwEkn1V7g\nmXvvqJjSdW7ZiJUPj+VoYQnnPvt1xJGigV6c96P/9Y2vLa0wbV4MI0zzikq5+uVFrMzKBaxS/uGA\nrpFgVfMkV7ASk1JKQc00ii4HOhlj+gN/Az6OlNAY87IxJsMYk5GWllYDh66+Jg08tG/agDdvGlIn\nxz9aWMLizWUl+5+/nlnuRlCifdWVUjGodkA3xhw2xhy1X38GeESkZbVzdpx1aGZV0dw7pvtxPe6u\nQ+UXl/7Xom1B7yvTV93rNTHPPaOUcpZqB3QRaSNiVQCLyBD7Ow9U93uPt1apyax4aAx3ntXVv61/\nx6a1ftytIfXwQFAXSYCiSkwP8OycH+j10EwOFxRHT6yUcpRYui2+CywCeohIlojcJCK3i8jtdpIr\ngDV2HfoU4GpjYhkEf+Jp2jCRhISyfuKf3Dk8aP+jF51CyyhzwlTWgRgaY3/7n5X8/PWllHoN+w4X\n8Nj0dew/Gn5mx3e/tXq6+FZdCjRt5S6d3VEpB4ull8uEKPtfAF6osRydYKZen8FNb2Ry28guXH96\nOmN6t+b0P8+t8DNXDOrAofwi5qzfV2G6lCR3TA2xvt4zo56Zx46DVhXN1AVb+PjO4bRtkkzrxmVL\n5BXa3SK9IffUvMISfvXud/Roncqs34wM2meMYduBfNIDJjOrLwqKSzEGHU2rFHE6UrQyzunVms2P\nn8/EcT0Ba+HoHq1TARjRLXxTwTNX9qejPQf71YM70jBCsOnTvnGl8uIL5j6XvLiQS15cyIxVZVP4\n+gY+hfZ3z7O7UG7Ye6Tc9762cCujnvmK1XZPm/pk2BNf6mhapWwa0MP4ZuLZzLx7hP99QoJgNxMA\n0CIlEYDHL+0b8Tt8BeRurVN56ZpBYdP0bd+k2nndnVvAne+UTeFbFtCDG0Yraij91n4CCJ2qoD7I\nCVO1pFS80oAeRrumDejZJnLpecqEgTx1eT9/KRygdePwdesCuBMk7L4hnVtEPIYrwmei8d1IQgN6\n6KhVgNcXbuGtxdsotT8Ueswt+/PYd6SAG177lv/9kF2l/Ciljp+4nG2xulqmJPGTwR0B+O8vTudI\nQQk926Qy5PEvuWaoNWDK1y4sAl1bp9C/Y1NW7jjk/47x/dsxtEvziMdIcieEDcKxKijxkptfTP8/\nzubPl/WlW+sU/773M3cwoGNTPl6xi1KvoVWqdTMKDehnPfOV//XCTfvZ+Kfzq5wfp8nJK2J3bgG9\n21Wu2kyp2qQl9GoaeFIzRnZPo1XjZLb++QImX2JVw/iaJAWrS2Roj5kpVw8gNTny5GAuqVoJ3aeg\nuJSN+6z68neX7gi6Ofz+g1WMffZrVuw4xO7cgoASOqzKOkT6xBl8sCwr6Pt8C3Gs2ZnLBVPmR2zM\nffTTtTwyLexAYUe5+MWFQfP2KHUi0IBeSxLsgJwQpupkzaPn+uvkX752EFdldOTaoZ1455bT/Gl8\n8XzCkI5VOv7XP2Szz160ev2uw/753EPtP1ro7xljDPwn0wrkv/3PynJpC4pLufBvC1i76zCZWw+W\n2//l+r28tnArr3+ztUp5rk/qY3uDqp456/byyvzNdZ2NCmmVSy25e3Q3CktKuXJQWUC+ZURn9h4u\nJCWp7Nc+9pQ2jD2lTbnPu+3pF9s0jj7J2JOX9+UPH64O2vb2ku1szrYGLRWVevlTwLqmofbYfdOL\nS02FC3088VnZd4SONCj1Gm56IzNqXkNt2Z/Hhj1HOK9P+d+BUieSm9+0/r5vHtGljnMSmZbQa0nT\nhok8cVm/oP7Rky7ozZQJA2P6/G/thajbNrWqct69ZWi5NHeMOpmLB7SLWHVzIK9s8NHOMFMM+Pfl\nWPuKS714KwjobwRMSbAjJ5+MyXPYnH2UO95axsin5kX8nG8GSYBN+44E5eWsZ77i9reWRfysqr7d\nuceCpmNWzqUB/QSz+pGxbJh8HhOGdOT924Zx8YB2AGEbUK/K6MjzVw8k2RP+Mv6w92jY7aF8XR2L\nSrwVltADvbd0B/uPFvLW4u18vmZPuRvG8u05fGjXw9/59nJ6PjiTtxZvY/Rfv2Z4mIFZvvlqVmfl\n8tHyLI4VlXLrm5ms2HGoXI+dyrr739+RPnFGlT771uJtfLc9h5+9spj1u8uvO1vRDTBW5z8/n/eX\n7qj290Qy7Im5jP/bglr7/kBTvtxI+sQZlOhauXVCA/oJJjXZQ5LbhYgwpHNzktxWCV9EuPmMzkFp\nPW7r8p3VoxUX9W8X0/e/f9swNkwOv15JVs4xPlyeFXZfKF8ja6SJwy77+zfca9fDz1y7B4AHPg67\n6BWAv45//AsLuOf9lXz5/V5mr9vLJS8u5A8friqXvrCklL99uTGmvH5cjZWfHvh4DZf+/RsWbjoQ\ntrE39AaYm19cqSBvjGHd7sP8Psw51qStB6pW558+cQZ/mb0h5vQvztsEVLxWrqo9GtDrkXvGdue2\nM7vw1W9H8fD43v5FPESEKRMGcuvI6HV7vptEx+bl6+afnfNDzHnZYk8qtnhzzczDdii/iBfmlgXo\nrzaU9XtfuKn8Mf797Q7+8kXs+a0JS7YcLNcoFriaVE5eEf3/OJvnYrzRQNmasgDZRwqrPalaqdfw\n9682hZ3Lx6eguDSmKpjCEuum/be5m1i36zDpE2ewfHtOhZ/xNeYX65TPQXLzi0mfOINPVuys1eNo\nQK9HGia6uW9cL9JbNuLG4Z3L7U+oRFfHf/ws/OjVytq4r+JqnR0x9gaZtXYvz8wuC9CB3SabNSzf\nRhD6ZPDY9HW8s2Q73/y4n6VbD4YtJUeaMy73WHHYJ41wS/9NnrE+qKRe4i37nK/aabb9RBLouTk/\nBI1DMMZw4Ghh0AjewX+aQ79HZse8etbewwVssn//G/YcwRjDih05PDVzg//pKJzxf1sQtCJWJLkB\nC63M22DNS/TFur0Vfkaw/gajzRC67UAef529IeI1cZotB6wC0NQFW6KkrB7t5eIgviXvHrqwN1k5\nx/C4hDO7p/HTV8ovfZforp17ec82qXy/p2y+mK82hJ+gLCeviOmry+agCVc/HWjnoWNBywqG5j/0\nP8rtZ57MxHE9gwL71AVbyvVQMMbQ/9HZXNivLYnuBFo0SsTjSuDu0d0jruUa2C0zME2e3Tc/JclN\ncakXj91Taf/RQp6bs5Hn5mzkzZ8PYWT3NJ6ds5EpX25k+l1nAJAg4PuqC6bMZ9ovzyAtNXj0sTGG\nzvd9RodmDcjKKWuzeOPnQ7j+1W956op+dLEnWPvmx/1h8w7Rb8I+gStn+X6PvvERPR/8nLG925Rr\n5C8roUcO6AXFpZz59FcAXDGoI1+s38u+wwXcd36vcmk37DnC5Bnr+L/rMth+MJ+HP1nLy9cNqnAM\nRyxWZ+XiNaZKU2QbY4KmAqmM6o0uiU4DuoP46rUbJrp4aHzvCtPGMrPAyWmN+DG7/HztFWkaUpp+\n8JPwg4wGPvZF0Pt1FQT0jfuO+htSu7VK4Y5RJzNzTflScKCX/vcjVw3uyJqdZROOTZ6xnrzCUj5b\nvds/4+ThY1YQnh4wwRlY8+wMOzny1Aw+f/hwFUluF1MmDPQPtlq/+zDdJn3O+7cNY0jn5mwIuMHd\n99FqFk48m6l21U1WjvUE43Yl+Eu1u3ML+On/LeaLe84Eym4UvpG8gcEcYMOew/a/R/wzb/r+FgJL\nwCWlXn932FgcCqi2CZ0eoqDYy7SVu5gyYSC7c4/RpnEyIuIPWBUF9MAxEQkJ1tMVEDagP/DxapZu\nzWHljkP8cfo61u46zOqsXE7vWr01dMa/YDUSb/3zBVHTFpV4+dOMdf73xaWGRHflQvPxehLRKhcH\nybd7g0SaSjZwkjBXQvClv2WEVYUTWGLxGvC4KveHW9XVkjbFWGrcuO8o97y/km9+jF53f9YzX5F9\nJHje+Gfn/MCGvUd4e4nVBfPbMAOkAO54eznjno8+EnTW2r1MW7mLx6av8w/k8i0h+O0WK4+BgXHn\noWOs2HHIn+ZNuyto6NNAYCm6zyOz6PPILP8AsFC++mq3S7j+1W/D7gPrhlaR8X9bwO8CqmoCq1x8\n5xY6L9Er8zcz7Im5vPz1ZuZvzPaf16Z9RzHGkF9Ugtdr7MBs/a7zAkYZR1tesSjg3HLsqqiVWbn+\nNpxYGGPYnB3+7+uvAQ2+RwqK/T2qbnjtW+7/rzW2Y+73+4K67FZmBTF/HnwvqjkCPBoN6A5ysd3T\n5dSTmoXdHzh4J71FQ247s1M2Qk0AABFHSURBVAuf3Dmcu87uyvWnpwNwa0CVRKnXMClMqQmgRaPE\nsNsjjUg9p2erqPmvDa99E77OctJ/17DjYD4PfxK5583u3NgXA5m6YEvQNMYAyR4XRSXeoNkwwZr2\n2Md3YwpXvfP2km18/UM2xlgDua785zdhj+2r1koMKX1vO5AXdIN9/Zut/qAazuqdufxnWRYLN1nV\nNYEB/Z0l1sIpoSOffTeJ//2QzbVTy24mN72RyXnPzaf3Q7OYPGM9by3e7h/cFjhtREW9YUpKvRy1\nG28n/XeNPyg+OfP7oHmGwPr9RQq0by3Zztl/+R/LtuWw/UA+cwLaAabM3cSRgmJy84vp+8hsLvu7\n9Tv+akO2/5zD3WzTJ86oVIcAXwFdq1xUzMae0iamR0iwesbcN84K1r5Sue+zY3qP4/wp83nggl6M\n6tGKNxdvY3N2Hi9dcyq3v7WcP13ah9G9WnPa418CVn31S//7kScu60vDRBe//veKcse7d2wPvvy+\n4gU/akPoHPKBRlQwGKoqFmwKrrdO9rhYu6vqc8xP+m/wzSbSuIKlW62eJ+6Qpy5fPXWgFdvLGmbP\n+ctXPHVFfwZ1Ci4ALPrxAMWlXh79dF3ox3l61gYaJ5cPG+HGCvjm3vctqegLjN8FNA4HVkcdKyr1\nP13+74dsfvPeCn8DcWC7jI/Xa/w3mGteWcKizQd47JI+XHPaSYgIXq/hljcz/X93l/8j/A0xsIE4\ntOovJ68oqOEbYO5664bw+sKtbNmfx9WDO0asUz/t8TkM6NiUm844PqNLNaDHico0gia6E5hj198C\n3D+uF3e+s5wR3dKCbhiTL+nDgo37mTiuJ9cO60S7JlY96ubsPJ4P6brXPEKJPpJmDT2Vmuu8cbKb\nVY+cS35RCb0fmlWpY9WWBh4XOfmx9Vip7PmG446hemz6qrI++T9m53H/R6tJ9iT4n9AAXrD7kkcS\nrl3kWITqoECb7JJtoLve/c7/+rcfrOTFn57K4s0HylUdhfPJyp10aZlCssfFIru0/ODHazitc3O6\nt05l0eYD1S5EjHn2fww7Obi+fspc6/czc+0eZq7dQ/umDdh2MJ9LB7ZnS3YefTs0IXPrQVKTPew9\nXMistXu5blg6YN20dh06Rrum0af0qAoN6HHgq9+OIiVMqSpWo3u3ZsPkceW2XzO0E9cM7QQQ1AMl\n3ApNkUazRpL5wBhOvv8z//vTOjfnJxkdI3bHS/a47GO7aZjoqtbUw6HuHt2Nrfvz6N4mladmxj7I\nRgRy8mIL0jWxUEcsA4BWhqxK5StF3/N+5G6OsSiMYTTvsShpZqzazYxVsY/ofXXBVlbvzC3XEJ+V\nk8/kGes5L8wcSbG4+Y2l/tf7jxbx6cqKB6Y9/+VGlm3L4UF74Fznlo3K1fH72nI27D3C6X+eG/OT\ndGVpHXocSG/ZqMYXt67Iz+wg77Pk/nNITfbQp31j7jq7a9C+G4enh/2O0LnZR/VoxeWDOjD5kj5B\n2//+s1MBaNKg7D91YENb11YpxOrJy8OvQNWmcTLPXT2QO848OebvAqvxLNYSeqC1j55b6c9AWbfH\nqi6OUh2bK9FIWRNEyma8PBRyM3xx3o98/UO2v1GzsqKtBRzqaEi7UbgG27vfC66GrIkpI8LRgK5q\nXEqSmw/vOB2AT395Bq0bJ+NKEKbfNYJ7x/ZgyxPWQhk3Dk/n4fGncOWgDlG/0zeyNXRWxnN6tWJ0\nr9Y8d/UA/7bAhrY7z4o9CIeObuzZxlo71jd6U0T49JdnBE1zXJE/fLja32jYJmAh74qM79+ORknV\ne3CO1H/eSXq1aRzUaBto2baKR7PWtHDr9EZztCj64vBVoQFd1YpBnZqx9c8X0LdD+XVTRYRNfxrH\nQxdafeWfvrJ/0P7RvYJ7xFw5qAPn9GwNWKtFzbp7pH9fktvFK9dncEq78OuzNmuYyLIHRvtXkgJY\n+dDYsGkvHdien2R04MWfnkqLRom88NNTGd61BVcETIHct0MTTj+5JY+FPClE8+EvTufG4elBA3FC\nBw4BPHNlP4CYbxrRdLOfUAZUYQAN1FzvpLNruJdT2yZlN8jurWN/CjtRTKyluXs0oKs64XYlROwZ\n8PK1GUHvn76yf1Df+h5tUvnuwTHlVoEK9filfTmzexotUpL8K0kBNAkzlQBAoyQ3T13Rnwv6tWXZ\ng2Po2iqFt28eGrZB1zeb4NWDgxcgad4okR6tU4O2XTygHe2bNuDh8adwUf92nN/Xesq4sF/bct/r\nm4zt9JMjD5z54PZhjA+YjC20fSLw1+rrwdIv4MZ6yYDYJnIDaGxXZT1j33Q72yNRK+uGgEbXmhBY\nxRZuaulYzLlnZIX7n7y8b4ULuT9xWeRF4qNpHeMTW2VFDegi8qqI7BORsB12xTJFRDaJyCoRObXm\ns6mczrfoR+YDo8Ou8hSqWaPEqMO2Lzu1fdQh2v07NuX1Gwfz+KWV+8/pq9Zo0yT4P+ayB0Yz7a6y\nG83s34zk+auDh8c/d9VA3r75NLqHBP5IuoW0A2SkN+d39nz5UBZsfdoGBAvfiMrG9lD5tk2S/UE6\nkrG9W/tf+/qxN0p08e2kc/jsVyOi5veCMDeqFinWTTHcpHCRrHpkLLeM6MzSSaP5xSir6uyV6zJY\nOmk0zeyb7H3jetKiCu1DT13Rj66tUrltZBemXl9WgJj9m5HcdEZnbjg9nasGn8S7t1o3i3vHdGf5\ng2Po0Kws/1dllN3Mf3du2fUIdXGYG+hdZ3erdJ5jEUtl3evAC8CbEfaPA7rZP6cB/7D/VSpmmQ+M\nxpjgUa4pSW6Gdok+/D6SpJCumlcM6lBunu5opfxIfnZaJ7KPFnLbyJN5bo7VRXP6XWcgIngC+oOH\nC9qJ7gSGd23Jvu8qnqp4+l1nsHZXLr3aNuaiFxbSwOPixZ9ZN4eTWjRkzaPn0tDjIiFB6N22MceK\nS7lgygIy0pszbeUubhvZhfH92tKyUSJtmzbghXmbcLuEP5zXk04tGvmH3H9853A8LqFrqxSMsUaD\ndp30OWA1qAO0b9aAVqnWjSI1yc2RgMFBD4/vzagerRjz1/9xycD2PH1FP0Z0bcnEj8oaJds2sQLh\nTwZ19M+S+f1j5/HT/1vM8u2HuLBfW6av2s37tw3jJ/9cBFg3oUkXWNVyvz+vJ9cM7eTv7ucfqGPf\nr089qSnLA/rYB7qgb1vmbdgX1PPpJ3YwDp1uoHGyhwcvLJs2IyXJzfePnUeS23qifPSiU7jpjUye\nvap/UMHjmtM68fSsDbgTpNyUyn++rB892zTmyZnfA9bTUmW78cYqakA3xnwtIukVJLkYeNNYkxUs\nFpGmItLWGLO7gs8oFcTX7TDQmir29njtxsF8tmp3udJ5aEm2OhokuvwDs3z62I/nsTxhAFzQtx3r\ndx9heNeWYftd92nfxP+dc+89k04tGgX1YAlcyrBLmlWKf+eW0+jfoWlQXf3pXVtSUupldK/W3HnW\nyTRKcnPTGZ25YlAH3AlSYSPsPWO6c1aPNPp1KHsaenB8b37Yc4S3lmyjoNjrn/lz0+Pn+9OcZdeZ\nN2+UyPIHxwBWiTsl0c13Ow5xUf92JHtc/Of20ynxeikpNdx+5sn+8w0nsO+2r/dSegvrhnPLiC7c\n8XbZiNz2TRvw58v7MqJbGmB1G9x+MD/i4CKf1DDdewP/Ns/p1Tpsl8OGSVaaKzM6Mr5/W9o1aUBq\nshsRoUGiiztGnewP6JFGcteEmuiH3h4IXG4ly95WLqCLyK3ArQAnnXRS6G6lasRZPVpxVo+KG+Ee\nvLA3B/MKK0wTqwlDTgp6FI9VojuB++0S4rRfDkcqGBjuC9jRRKp7d7sSeOX64LaJJlGqXnx5PC3k\nKclXur3r7G7+OdND+aZyDjwjX7XPqzcM9m9zJQiuBBdJ7rIb4qy7R0adL2XCkI70aJPCoE7WSl7j\n+rZl6aTRDP7THAAuP7W9P5iD1QDdKCn8HEeBwo2hiIXHlcCKh8aQkuSOOAHa5sfP58PlWVxUiTaM\nyjquA4uMMS8DLwNkZGQ4v2+VOmHdFLL6U3VEahwLt2xgJIEl4BPBfeN6Rp2i1mpcDp+mZUoi1w7t\nxFUhjcax6NEmetuCiPiDuU9gr6FfnVO+jrpBmKfAcN9bGa/ekOGf6K5pw4qrURIShCszKv/7qIya\nCOg7gcBcdrC3KRW3vntwjP8xvD66rZKDqEKJSKW7dtYUEcKWkisK1reM6FxuBtJYnN2zdfREx1FN\nBPRpwC9F5N9YjaG5Wn+u4l2zWmr0UhVbcv855ab4DfTU5f38Db2BfI2v9V3UgC4i7wKjgJYikgU8\njP2cZYx5CfgMOB/YBOQDN9ZWZpVSqiLR+nf/pApVQPVJLL1cJkTZb4A7ayxHSimlqkRHiiqllENo\nQFdKKYfQgK6UUg6hAV0ppRxCA7pSSjmEBnSllHIIDehKKeUQYkzdTKkiItnAtip+vCWwvwazUx/o\nOccHPef4UJ1z7mSMSQu3o84CenWISKYxJiN6SufQc44Pes7xobbOWatclFLKITSgK6WUQ9TXgP5y\nXWegDug5xwc95/hQK+dcL+vQlVJKlVdfS+hKKaVCaEBXSimHqHcBXUTOE5ENIrJJRCbWdX5qioh0\nFJF5IrJORNaKyK/t7c1F5AsR2Wj/28zeLiIyxf49rBKRU+v2DKpGRFwi8p2ITLffdxaRJfZ5vSci\nifb2JPv9Jnt/el3muzpEpKmIfCAi34vIehEZ5uTrLCK/sf+m14jIuyKS7MTrLCKvisg+EVkTsK3S\n11VErrfTbxSR6yuTh3oV0EXEBbwIjAN6AxNExBlrR0EJcK8xpjcwFLjTPreJwJfGmG7Al/Z7sH4H\n3eyfW4F/HP8s14hfA+sD3j8JPGuM6QrkADfZ228Ccuztz9rp6qvngZnGmJ5Af6zzd+R1FpH2wK+A\nDGNMH8AFXI0zr/PrwHkh2yp1XUWkOdaqcKcBQ4CHfTeBmBhj6s0PMAyYFfD+PuC+us5XLZ3rJ8AY\nYAPQ1t7WFthgv/4nMCEgvT9dffnBWlD8S+BsYDogWKPn3KHXG5gFDLNfu+10UtfnUIVzbgJsCc27\nU68z0B7YATS3r9t04FynXmcgHVhT1esKTAD+GbA9KF20n3pVQqfsj8Mny97mKPZj5kBgCdDalC26\nvQfwLTPuhN/Fc8DvAa/9vgVwyBhTYr8PPCf/+dr7c+309U1nIBt4za5qekVEGuHQ62yM2Qk8A2wH\ndmNdt2U4/zr7VPa6Vut617eA7ngikgJ8CNxtjDkcuM9Yt2xH9DMVkQuBfcaYZXWdl+PMDZwK/MMY\nMxDIo+wxHHDcdW4GXIx1I2sHNKJ8tURcOB7Xtb4F9J1A4LLdHextjiAiHqxg/rYx5iN7814RaWvv\nbwvss7fX99/FcOAiEdkK/Bur2uV5oKmI+BYvDzwn//na+5sAB45nhmtIFpBljFliv/8AK8A79TqP\nBrYYY7KNMcXAR1jX3unX2aey17Va17u+BfSlQDe7hTwRq3FlWh3nqUaIiABTgfXGmL8G7JoG+Fq6\nr8eqW/dtv85uLR8K5AY82p3wjDH3GWM6GGPSsa7jXGPMz4B5wBV2stDz9f0errDT17tSrDFmD7BD\nRHrYm84B1uHQ64xV1TJURBraf+O+83X0dQ5Q2es6CxgrIs3sp5ux9rbY1HUjQhUaHc4HfgB+BCbV\ndX5q8LzOwHocWwWssH/Ox6o//BLYCMwBmtvpBavHz4/AaqxeBHV+HlU891HAdPt1F+BbYBPwHyDJ\n3p5sv99k7+9S1/muxvkOADLta/0x0MzJ1xl4FPgeWAP8C0hy4nUG3sVqJyjGehK7qSrXFfi5ff6b\ngBsrkwcd+q+UUg5R36pclFJKRaABXSmlHEIDulJKOYQGdKWUcggN6Eop5RAa0JVSyiE0oCullEP8\nPwdwnnP/kNqZAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZjwAoDYjEey",
        "colab_type": "text"
      },
      "source": [
        "# RNN: sampling\n",
        "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.341196Z",
          "start_time": "2018-08-13T20:26:55.323787Z"
        },
        "id": "VUBPIvfpjEey",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_t = tf.placeholder(tf.int32, (1,))\n",
        "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
        "\n",
        "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
        "# We reuse all parameters thanks to functional API usage.\n",
        "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
        "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
        "next_probs, next_h = rnn_one_step(x_t, h_t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.346422Z",
          "start_time": "2018-08-13T20:26:55.342659Z"
        },
        "id": "5cAxpc0wjEe1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
        "    '''\n",
        "    This function generates text given a `seed_phrase` as a seed.\n",
        "    Remember to include start_token in seed phrase!\n",
        "    Parameter `max_length` is used to set the number of characters in prediction.\n",
        "    '''\n",
        "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
        "    s.run(tf.assign(h_t, h_t.initial_value))\n",
        "    \n",
        "    # feed the seed phrase, if any\n",
        "    for ix in x_sequence[:-1]:\n",
        "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
        "    \n",
        "    # start generating\n",
        "    for _ in range(max_length-len(seed_phrase)):\n",
        "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
        "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
        "        \n",
        "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:58.458115Z",
          "start_time": "2018-08-13T20:26:55.347900Z"
        },
        "id": "wKDa8HuYjEe4",
        "colab_type": "code",
        "outputId": "71f30e47-3090-4366-9cf6-adb36618dbe7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "# without prefix\n",
        "for _ in range(10):\n",
        "    print(generate_sample())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Jarky\n",
            " Kaulbint\n",
            " Fasxalth\n",
            " Anarinne\n",
            " Dendresre\n",
            " Kred\n",
            " Sragiu\n",
            " Sonnat\n",
            " Torie\n",
            " Famlee\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:01.986726Z",
          "start_time": "2018-08-13T20:26:58.459810Z"
        },
        "id": "5cGCviMejEfD",
        "colab_type": "code",
        "outputId": "c5ceb74c-c9b7-4e5e-e8b7-4e0bcfb89cd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "# with prefix conditioning\n",
        "for _ in range(10):\n",
        "    print(generate_sample(' Trump'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Trumpiesy\n",
            " Trumpees\n",
            " Trumperlo\n",
            " Trumpol\n",
            " Trumpiy\n",
            " Trumposte\n",
            " Trumpae\n",
            " Trumpe\n",
            " Trumpis\n",
            " Trumpie\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgllFxhojEfG",
        "colab_type": "text"
      },
      "source": [
        "# Submit to Coursera"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:02.004926Z",
          "start_time": "2018-08-13T20:40:02.000821Z"
        },
        "id": "HXk3kLEEjEfG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# token expires every 30 min\n",
        "COURSERA_TOKEN = \"3L0MWIHEzGiqqCUm\"\n",
        "COURSERA_EMAIL = \"f20140751@hyderabad.bits-pilani.ac.in\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:18.923357Z",
          "start_time": "2018-08-13T20:40:03.549343Z"
        },
        "id": "YdtP165EjEfJ",
        "colab_type": "code",
        "outputId": "1a1fbab0-d2e2-472c-a954-58366b183802",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "from submit import submit_char_rnn\n",
        "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
        "submission = (history, samples)\n",
        "submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************************\n",
            "\n",
            "Submitted to Coursera platform. See results on assignment page!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrkO22SljEfM",
        "colab_type": "text"
      },
      "source": [
        "# Try it out!\n",
        "\n",
        "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
        "\n",
        "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
        "\n",
        "* Novels/poems/songs of your favorite author\n",
        "* News titles/clickbait titles\n",
        "* Source code of Linux or Tensorflow\n",
        "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
        "* Melody in notes/chords format\n",
        "* IKEA catalog titles\n",
        "* Pokemon names\n",
        "* Cards from Magic, the Gathering / Hearthstone\n",
        "\n",
        "If you're willing to give it a try, here's what you wanna look at:\n",
        "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
        "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
        "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
        "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
        "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
        "\n",
        "__Good hunting!__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "Zpr1QWZzjEfN",
        "colab_type": "text"
      },
      "source": [
        "# Bonus level: dynamic RNNs\n",
        "\n",
        "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
        "\n",
        "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
        "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
        "\n",
        "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.975354Z",
          "start_time": "2018-08-13T20:27:12.737529Z"
        },
        "id": "3TDqPqk0jEfO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
        "    def call(self, input, state):\n",
        "        # from docs:\n",
        "        # Returns:\n",
        "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
        "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
        "        return rnn_one_step(input[:, 0], state)\n",
        "    \n",
        "    @property\n",
        "    def output_size(self):\n",
        "        return n_tokens\n",
        "    \n",
        "cell = CustomRNN(rnn_num_units)\n",
        "\n",
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "    \n",
        "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
        "\n",
        "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
        "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFFLRyA4jEfQ",
        "colab_type": "text"
      },
      "source": [
        "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
        "\n",
        "You can also use any pre-implemented RNN cell:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.981697Z",
          "start_time": "2018-08-13T20:27:12.977590Z"
        },
        "id": "2xgw2LxTjEfR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
        "    if obj.endswith('Cell'):\n",
        "        print(obj, end=\"\\t\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:13.168207Z",
          "start_time": "2018-08-13T20:27:12.986884Z"
        },
        "id": "h1QmYQAOjEfU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "\n",
        "inputs_embedded = embed_x(input_sequence)\n",
        "\n",
        "# standard cell returns hidden state as output!\n",
        "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
        "\n",
        "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
        "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}